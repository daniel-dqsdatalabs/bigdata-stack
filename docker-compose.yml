services:
  # postgres:
  #   image: postgres:latest
  #   container_name: postgres
  #   ports:
  #     - "5432:5432"
  #   environment:
  #     - POSTGRES_USER=${POSTGRES_USER}
  #     - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
  #     - POSTGRES_DB=northwind
  #   volumes:
  #     - ./docker/postgres/databases:/docker-entrypoint-initdb.d
  #     - ./docker/postgres/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
  #   command: ["postgres", "-c", "log_statement=all"]
  #   networks:
  #     - dqsdatalabs

  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_DOMAIN=minio
    volumes:
      - minio-data:/data
    command: ["server", "/data", "--console-address", ":9001"]
    networks: &default-network
      - dqsdatalabs

  minio-mc:
    image: minio/mc:latest
    container_name: minio-mc
    environment:
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
    volumes:
      - ./docker/minio/minio-entrypoint.sh:/usr/bin/entrypoint.sh
    entrypoint: /bin/sh /usr/bin/entrypoint.sh
    depends_on:
      - minio
    networks: *default-network

  spark-master: &spark-service
    build:
      context: ./docker/spark
      dockerfile: Dockerfile
    image: spark-sandbox:latest
    container_name: spark-master
    environment:
      - SPARK_MASTER_HOST=spark-master
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    networks: *default-network

  spark-worker:
    <<: *spark-service
    container_name: spark-worker-1
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8082
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    networks: *default-network
    deploy:
      resources:
        limits:
          cpus: "3.0"
          memory: 2G

  flink-jobmanager: &flink-service
    build:
      context: ./docker/flink
      dockerfile: Dockerfile
    image: flink-sandbox:latest
    container_name: flink-jobmanager
    depends_on:
      - minio
    ports:
      - "8081:8081"
    expose:
      - "6123"
    environment:
      FLINK_MODE: jobmanager
      FLINK_CFG_REST_PORT: 8081
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
    command: jobmanager
    networks: *default-network

  flink-taskmanager:
    <<: *flink-service
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    environment:
      FLINK_MODE: taskmanager
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
    command: taskmanager
    ports: []
    networks: *default-network

  kafka:
    image: apache/kafka:4.0.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
      - "9094:9094"
    environment:
      - KAFKA_CLUSTER_ID=dqsdatalabs-kafka-cluster
      - KAFKA_NODE_ID=1
      - JAVA_OPTS=-Xms512m -Xmx1g
    volumes:
      - ./docker/kafka/server.properties:/etc/kafka/server.properties
      - kafka-data:/tmp/kraft-combined-logs
    command:
      [
        "sh",
        "-c",
        "if [ ! -f /tmp/kraft-combined-logs/meta.properties ]; then /opt/kafka/bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c /etc/kafka/server.properties; fi && /opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties",
      ]
    networks: *default-network

  kafka-producer:
    build:
      context: ./docker/kafka
      dockerfile: Dockerfile.producer
    image: kafka-producer:latest
    container_name: kafka-producer
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    networks: *default-network

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8090:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=dqsdatalabs-kafka-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on:
      - kafka
    networks: *default-network

  jupyter:
    build:
      context: ./docker/jupyter
      dockerfile: Dockerfile
    image: jupyter-sandbox:latest
    container_name: jupyter-notebooks
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
    volumes:
      - ./docker/jupyter/datasets:/home/jovyan/datasets
      - ./docker/jupyter/notebooks:/home/jovyan/notebooks
    networks: *default-network

  portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer
    restart: always
    ports:
      - "8089:8000"
      - "9010:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer-data:/data
    networks: *default-network

networks:
  dqsdatalabs:
    name: dqsdatalabs
    driver: bridge
    ipam:
      config:
        - subnet: "172.50.0.0/24"
          gateway: "172.50.0.1"

volumes:
  minio-data:
  kafka-data:
  portainer-data:
