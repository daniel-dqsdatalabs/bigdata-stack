services:

  postgres:
    image: postgres:latest
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=northwind
    volumes:
      - ./docker/postgres/databases:/docker-entrypoint-initdb.d
      - ./docker/postgres/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
    command: ["postgres", "-c", "log_statement=all"]
    networks:
      - dqsdatalabs

  
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"      
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_DOMAIN=minio
    volumes:
      - minio-data:/data
    networks:
      - dqsdatalabs
    command: ["server", "/data", "--console-address", ":9001"]

  minio-mc:
    image: minio/mc:latest
    container_name: minio-mc
    environment:
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
    volumes:
      - ./docker/minio/minio-entrypoint.sh:/usr/bin/entrypoint.sh
    entrypoint: /bin/sh /usr/bin/entrypoint.sh
    depends_on:
      - minio
    networks:
      - dqsdatalabs
  spark-master:
    build: 
      context: ./docker/flink
      dockerfile: Dockerfile
    image: spark-sandbox:latest
    container_name: spark-master
    environment:
      - SPARK_MASTER_HOST=spark-master
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    networks:
      - dqsdatalabs

  spark-worker:
    build: 
      context: ./docker/spark
      dockerfile: Dockerfile
    image: spark-sandbox:latest
    container_name: spark-worker-1
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8082
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    networks:
      - dqsdatalabs
    deploy:
        resources:
          limits:
            cpus: "3.0"
            memory: 2G

  flink-jobmanager:
    build: 
      context: ./docker/flink
      dockerfile: Dockerfile
    image: flink-sandbox:latest
    container_name: flink-jobmanager
    depends_on:
      - minio
    ports:
      - "8081:8081"
    expose:
      - "6123"
    environment:
      FLINK_MODE: jobmanager
      FLINK_CFG_REST_PORT: 8081
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
    command: jobmanager
    networks:
      - dqsdatalabs

  flink-taskmanager:
    build: 
      context: ./docker/flink
      dockerfile: Dockerfile
    image: flink-sandbox:latest
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    environment:
      FLINK_MODE: taskmanager
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager
    command: taskmanager
    networks:
      - dqsdatalabs
  
  kafka:
    image: apache/kafka:4.0.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
      - "9094:9094"
    environment:
      - KAFKA_CLUSTER_ID=dqsdatalabs-kafka-cluster
      - KAFKA_NODE_ID=1
      - JAVA_OPTS=-Xms512m -Xmx1g
    volumes:
      - ./docker/kafka/server.properties:/etc/kafka/server.properties
      - kafka-data:/tmp/kraft-combined-logs
    command: ["sh", "-c", "if [ ! -f /tmp/kraft-combined-logs/meta.properties ]; then /opt/kafka/bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c /etc/kafka/server.properties; fi && /opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties"]
    networks:
      - dqsdatalabs

  kafka-producer:
    build:
      context: ./docker/kafka
      dockerfile: Dockerfile.producer
    image: kafka-producer:latest
    container_name: kafka-producer
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    networks:
      - dqsdatalabs

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8090:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=dqsdatalabs-kafka-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on:
      - kafka
    networks:
      - dqsdatalabs

  jupyter:
    build: 
      context: ./docker/jupyter
      dockerfile: Dockerfile
    image: jupyter-sandbox:latest
    container_name: jupyter-notebooks
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
    volumes:
      - ./docker/jupyter/datasets:/home/jovyan/datasets
      - ./docker/jupyter/notebooks:/home/jovyan/notebooks
    networks:
      - dqsdatalabs

portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer
    restart: always
    ports:
      - "8089:8000"
      - "9010:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer-data:/data
    networks:
      - dqsdatalabs

networks:
  dqsdatalabs:
    name: dqsdatalabs
    driver: bridge
    ipam:
      config:
        - subnet: "172.50.0.0/24"
          gateway: "172.50.0.1"

volumes:
  minio-data:
  kafka-data:
  portainer-data:

